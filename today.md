# 2. HTTP的现状（未校对）

互联网上几乎所有内容都采用HTTP1.1作为通信协议。人们在该协议上投入了大量精力，并让基础架构受益于此。正因如此，基于HTTP协议构建新的方案会比重新建立新的协议容易得多。

**2.1. HTTP 1.1非常庞大**

当HTTP刚被创造出来的时候，它只被当作是一个相对简单直观的协议，但时间证明这种看法是错的。定义HTTP 1.0规范的RFC 1945共有60页，发布于1996年。而3年以后，定义HTTP 1.1规范的RFC 2616却一下增长到了176页。当我们在IETF制定新版规范的时候，该规范被拆分成了六个档案，它们总共的页数甚至更多（这就是RFC 7230和相关规范）。无论怎么讲，HTTP 1.1包含了太多细节和可选的部分，这也让他变得非常庞大。


**2.2. 过多的可选项**

HTTP 1.1包含了非常多细节和为将来扩展而预留的选项。过多的内容导致在现在的软件生态中，几乎没有任何实现真正实现了所有细节 - 甚至搞清楚“所有细节”到底有些什么都非常困难。这也导致了“没人用所以不实现 - 没有实现所以没人用”这样的恶性循环。

在此之后，当这些小众的功能被逐渐开发使用的时候，客户端和服务器交互的问题也就暴露了出来。HTTP Pipelining就是一个非常好的例子。

**2.3. 未能充分利用TCP协议**
  
  HTTP 1.1很难榨干TCP协议所能提供的所有性能。HTTP客户端和浏览器必须要另辟蹊径的去找到新的解决方案来降低页面载入时间。

  与此同时，人们也尝试去用新的协议来替代TCP，但结果证明这也非常困难。无奈之下，我们只能尝试同时改进TCP协议本身和基于TCP的更上层协议。

  我们也能通过更好的利用TCP来减少发送/接受数据时的延迟。下面几段将会讨论TCP的一些问题。
  
**2.4. 传输大小和资源数量**

如果仔细观察打开那些最流行的网站首页所需要下载的资源的话，会发现一个非常明显的趋势。近年来加载网站首页需要的下载的数据量已经超过了1.9MB。但在这里我们更需要关注的是：所需下载资源的数量也达到了100个。

正如下图所示，这种趋势已经持续了很长一段时间，并却没有减缓的迹象。该图表中绿色直线展示了传输数据大小的增长，红色直线展示了平均请求资源数量的增长。

**2.5 恼人的延迟**

HTTP 1.1对延迟非常敏感。部分原因是HTTP Pipelining还有很多问题，所以被大部分用户默认关闭。

虽然近几年来网络带宽增长非常快，但是与此相对，我们并没有看到网络延迟有对应程度的降低。在高延迟的连接上（比如移动设备），即使拥有高连接速率，也很难获得优质快速的网络体验。

另外一个需要低延迟的场景是某些视频，例如视频会议、游戏、和需要即时演算的流媒体。

**2.6 线头阻塞（Head of line blocking）**
  
HTTP Pipelining是一种在等待上一请求响应的时候，提前发送下一请求的技术。这就像你在超市收银台或者银行柜台排队时，你并不知道前面的顾客是干脆利索的呢，还是会跟收银员/柜员磨蹭到世界末日 - 这就是线头阻塞（Head of line blocking）。

当然，你可以在选择队伍时候就做好功课，去排一个你认为最快的队伍，或者甚至另起一个新的队伍。但不管怎么样，你总归得事前选择一个队伍，且一旦选定之后，就不能换队伍重排。

但当然没有完美的方案，另起一个新队伍会导致性能和资源的浪费。所以当队伍很少的时候，这种方法并不能扩展。

即使在2014年的今天，大部分浏览器也默认关闭了HTTP pipelining功能。

关于这个主题的细节，可以去阅读Firefox bugzilla的第[264354](https://bugzilla.mozilla.org/show_bug.cgi?id=264354)条
  