# 2. HTTP的现状（未校对）

互联网上几乎所有内容都采用HTTP1.1作为通信协议。人们在该协议上投入了大量精力，并让基础架构受益于此。正因如此，基于HTTP协议构建新的方案会比从底层建立新的协议容易得多。

**2.1. HTTP 1.1非常庞大**

HTTP刚诞生的时候只被当作是一个相对简单直观的协议，但时间证明这种看法是错的。定义HTTP 1.0规范的RFC 1945共有60页，发布于1996年。而3年以后，定义HTTP 1.1规范的RFC 2616却一下增长到了176页。当我们在IETF制定新版规范的时候，该规范被拆分成了六个文档，它们总共的页数甚至更多（这就是RFC 7230和相关规范）。无论怎么讲，HTTP 1.1包含了太多细节和可选的部分，这也让他变得非常庞大。


**2.2. 过多的可选项**

HTTP 1.1包含了非常多的细枝末节和为将来扩展而预留的选项。过多的内容导致在现在的软件生态中，几乎没有任何实现真正实现了所有内容 - 甚至搞清楚“所有内容”到底有些什么都非常困难。这也导致了很多最初不常用的功能，在后来很少会被实现，而那些最初实现了的功能，却又很少有人应用。

在此之后，当这些功能被逐渐用上的时候，客户端和服务器的互用性问题也就被暴露了出来。HTTP Pipelining功能就是一个非常好的例子。

**2.3. 未能充分利用TCP协议**
  
HTTP 1.1很难榨干TCP协议所能提供的所有性能。HTTP客户端和浏览器必须要另辟蹊径的去找到新的解决方案来降低页面载入时间。

与此同时，人们也尝试去用新的协议来替代TCP，但结果证明这也非常困难。无奈之下，我们只能尝试同时改进TCP协议本身和基于TCP的更上层协议。

我们也能通过更好的利用TCP来减少发送/接受数据过程中的暂停。下面几段将会讨论TCP的一些问题。
  
**2.4. 传输大小和资源数量**

如果仔细观察打开那些最流行的网站首页所需要下载的资源的话，会发现一个非常明显的趋势。近年来加载网站首页需要的下载的数据量已经超过了1.9MB。但在这里我们更需要关注的是：所需下载资源的数量也达到了100个。

正如下图所示，这种趋势已经持续了很长一段时间，并却没有减缓的迹象。该图表中绿色直线展示了传输数据大小的增长，红色直线展示了平均请求资源数量的增长。

![](trend.png)

**2.5 恼人的延迟**

HTTP 1.1对延迟非常敏感。部分原因是HTTP Pipelining还有很多问题，所以被大部分用户默认关闭。

虽然近几年来网络带宽增长非常快，但是与此相对的是，我们并没有看到网络延迟有对应程度的降低。在高延迟的连接上（比如移动设备），即使拥有高连接速率，也很难获得优质快速的网络体验。

另外一个需要低延迟的场景是某些视频，例如视频会议、游戏、和需要即时演算的流媒体。

**2.6 线头阻塞（Head of line blocking）**
  
HTTP Pipelining是一种在等待上一请求响应的时候，提前发送下一请求的技术。这就像你在超市收银台或者银行柜台排队时，你并不知道前面的顾客是干脆利索的呢，还是会跟收银员/柜员磨蹭到世界末日 - 这就是线头阻塞（Head of line blocking）。

当然，你可以在选择队伍时候就做好功课，去排一个你认为最快的队伍，或者甚至另起一个新的队伍。但不管怎么样，你总归得事前选择一个队伍，且一旦选定之后，就不能换队伍重排。

但当然没有完美的方案，另起一个新队伍会导致性能和资源的浪费。所以当队伍很大的时候，这种方法并不能扩展。

即使在2014年的今天，大部分桌面浏览器也默认关闭了HTTP pipelining功能。

关于这个主题的细节，可以去阅读Firefox bugzilla的第[264354](https://bugzilla.mozilla.org/show_bug.cgi?id=264354)条
  